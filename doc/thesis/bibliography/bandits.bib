@article{Mahadevan2012SparseDescent,
    title = {{Sparse Q-learning with Mirror Descent}},
    year = {2012},
    journal = {arXiv.org},
    author = {Mahadevan, Sridhar and Liu, Bo},
    volume = {cs.LG},
    url = {http://arxiv.org/abs/1210.4893},
    isbn = {9780974903989},
    arxivId = {abs/1210.4893}
}

@article{Szepesvari2010,
author = {Szepesv{\'{a}}ri, Csaba},
doi = {10.2200/S00268ED1V01Y201005AIM009},
file = {:Users/aksholokhov/Documents/Papers/Szepesv{\'{a}}ri/2010/Synthesis Lectures on Artificial Intelligence and Machine Learning/Szepesv{\'{a}}ri - 2010 - Algorithms for Reinforcement Learning.pdf:pdf},
issn = {1939-4608},
journal = {Synthesis Lectures on Artificial Intelligence and Machine Learning},
month = {jan},
number = {1},
pages = {1--103},
title = {{Algorithms for Reinforcement Learning}},
url = {http://www.morganclaypool.com/doi/abs/10.2200/S00268ED1V01Y201005AIM009},
volume = {4},
year = {2010}
}


@article{Lai1985,
author = {Lai, T. L. and Robbins, Herbert},
doi = {10.1016/0196-8858(85)90002-8},
file = {:Users/aksholokhov/Documents/Papers/Lai, Robbins/1985/Advances in Applied Mathematics/Lai, Robbins - 1985 - Asymptotically efficient adaptive allocation rules.pdf:pdf},
isbn = {0196-8858},
issn = {10902074},
journal = {Advances in Applied Mathematics},
mendeley-groups = {Mathematics/Machine learning/Reenforcement learning},
number = {1},
pages = {4--22},
title = {{Asymptotically efficient adaptive allocation rules}},
volume = {6},
year = {1985}
}

@article{Audibert2009,
author = {Audibert, Jean Yves and Munos, R{\'{e}}mi and Szepesv{\'{a}}ri, Csaba},
doi = {10.1016/j.tcs.2009.01.016},
file = {:Users/aksholokhov/Documents/Papers/Audibert, Munos, Szepesv{\'{a}}ri/2009/Theoretical Computer Science/Audibert, Munos, Szepesv{\'{a}}ri - 2009 - Exploration-exploitation tradeoff using variance estimates in multi-armed bandits.pdf:pdf},
isbn = {0304-3975},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Bernstein's inequality,Exploration-exploitation tradeoff,High-probability bound,Multi-armed bandits,Risk analysis},
mendeley-groups = {Mathematics/Machine learning/Reenforcement learning},
number = {19},
pages = {1876--1902},
title = {{Exploration-exploitation tradeoff using variance estimates in multi-armed bandits}},
volume = {410},
year = {2009}
}

@article{Papadimitriou1999,
author = {Papadimitriou, Christos H. and Tsitsiklis, John N.},
doi = {10.1287/moor.24.2.293},
file = {:Users/aksholokhov/Documents/Papers/Unknown/2018/Unknown/Unknown - 2018 - The Complexity of Optimal Queuing Network Control Author ( s ) Christos H . Papadimitriou and John N . Tsitsiklis Publi.pdf:pdf},
issn = {0364-765X},
journal = {Mathematics of Operations Research},
mendeley-groups = {Mathematics/Discrete Optimization/Packing Problems},
month = {may},
number = {2},
pages = {293--305},
title = {{The Complexity of Optimal Queuing Network Control}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/moor.24.2.293},
volume = {24},
year = {1999}
}

@article{Xia2015,
author = {Xia, Yingce and Li, Haifang and Qin, Tao and Yu, Nenghai and Liu, Tie-yan},
file = {:Users/aksholokhov/Documents/Papers/Xia et al/2015/Unknown/Xia et al. - 2015 - Thompson Sampling for Budgeted Multi-armed Bandits.pdf:pdf},
keywords = {Special Track on Machine Learning},
mendeley-groups = {Bandits/Bandits with Knapsacks},
number = {IJCAI},
pages = {3960--3966},
title = {{Thompson Sampling for Budgeted Multi-armed Bandits}},
year = {2015}
}

@article{Agrawal2014,
author = {Agrawal, Shipra and Devanur, Nikhil R},
file = {:Users/aksholokhov/Documents/Papers/Agrawal, Devanur/2014/Unknown/Agrawal, Devanur - 2014 - Bandits with Concave Rewards and Convex Knapsacks.pdf:pdf},
isbn = {9781450325653},
mendeley-groups = {Bandits/Bandits with Knapsacks},
pages = {989--1006},
title = {{Bandits with Concave Rewards and Convex Knapsacks}},
year = {2014}
}

@inproceedings{Li2010,
address = {New York, New York, USA},
archivePrefix = {arXiv},
arxivId = {1003.0146},
author = {Li, Lihong and Chu, Wei and Langford, John and Schapire, Robert E.},
booktitle = {Proceedings of the 19th international conference on World wide web - WWW '10},
doi = {10.1145/1772690.1772758},
eprint = {1003.0146},
file = {:Users/aksholokhov/Documents/Papers/Li et al/2010/Proceedings of the 19th international conference on World wide web - WWW '10/Li et al. - 2010 - A contextual-bandit approach to personalized news article recommendation.pdf:pdf},
isbn = {9781605587998},
issn = {9781605587998},
keywords = {contextual bandit,exploitation dilemma,exploration,personalization,recommender sys-,tems,web service},
mendeley-groups = {Mathematics/Machine learning/Reenforcement learning},
pages = {661},
publisher = {ACM Press},
title = {{A contextual-bandit approach to personalized news article recommendation}},
url = {http://arxiv.org/abs/1003.0146{\%}0Ahttp://dx.doi.org/10.1145/1772690.1772758 http://portal.acm.org/citation.cfm?doid=1772690.1772758},
year = {2010}
}

@article{Abbasi-Yadkori2011,
abstract = {OFUL: almost LinUCB, but with a direct proof},
author = {Abbasi-Yadkori, Yasin and Pal, David and Szepesv{\'{a}}ri, Csaba},
file = {:Users/aksholokhov/Documents/Papers/Abbasi-yadkori/2010/Unknown/Abbasi-yadkori - 2010 - Improved Algorithms for Linear Stochastic Bandits.pdf:pdf},
isbn = {9781618395993},
journal = {Neural Information Processing Systems},
mendeley-groups = {Mathematics/Machine learning/Reenforcement learning},
pages = {1--19},
title = {{Improved Algorithms for Linear Stochastic Bandits}},
year = {2011}
}



@article{Agrawal2013,
archivePrefix = {arXiv},
arxivId = {1209.3352},
author = {Agrawal, Shipra and Goyal, Navin},
eprint = {1209.3352},
file = {:Users/aksholokhov/Documents/Papers/Agrawal, Goyal/2013/Proceedings of the 30th International Conference on Machine Learning, Atlanta, Georgia, USA/Agrawal, Goyal - 2013 - Thompson Sampling for Contextual Bandits with Linear Payoffs.pdf:pdf},
issn = {1938-7228},
journal = {Proceedings of the 30th International Conference on Machine Learning, Atlanta, Georgia, USA},
mendeley-groups = {Mathematics/Machine learning/Reenforcement learning},
month = {sep},
title = {{Thompson Sampling for Contextual Bandits with Linear Payoffs}},
url = {http://arxiv.org/abs/1209.3352},
volume = {28},
year = {2013}
}

@article{Auer2003,
author = {Auer, Peter},
doi = {10.1162/153244303321897663},
file = {:Users/aksholokhov/Documents/Papers/Auer/2003/Journal of Machine Learning Research/Auer - 2003 - Using Confidence Bounds for Exploitation-Exploration Trade-offs.pdf:pdf},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {bandit problem,exploitation exploration,learning,linear value function,online learning,reinforcement},
mendeley-groups = {Mathematics/Machine learning/Reenforcement learning},
number = {3},
pages = {397--422},
title = {{Using Confidence Bounds for Exploitation-Exploration Trade-offs}},
url = {http://www.crossref.org/jmlr{\_}DOI.html},
volume = {3},
year = {2003}
}



@article{Na2011OptimalNetworks,
    title = {{Optimal demand response based on utility maximization in power networks}},
    year = {2011},
    journal = {Power and Energy Society General Meeting, 2011 IEEE},
    author = {Na, Li and Lijun, Chen and Low, Steven H and Li, Na and Chen, Lijun},
    pages = {1--8},
    url = {http://dx.doi.org/10.1109/PES.2011.6039082},
    isbn = {19449925},
    doi = {10.1109/PES.2011.6039082}
}

@article{Zhou2015,
abstract = {In this survey we cover a few stochastic and adversarial contextual bandit algorithms. We analyze each algorithm's assumption and regret bound.},
archivePrefix = {arXiv},
arxivId = {1508.03326},
author = {Zhou, Li},
eprint = {1508.03326},
file = {:Users/aksholokhov/Documents/Papers/Zhou/2015/Unknown/Zhou - 2015 - A Survey on Contextual Multi-armed Bandits.pdf:pdf},
mendeley-groups = {Bandits/Contextual Bandits},
title = {{A Survey on Contextual Multi-armed Bandits}},
url = {http://arxiv.org/abs/1508.03326},
year = {2015}
}


@book{Ghavamzadeh2015BayesianSurvey,
    title = {{Bayesian Reinforcement Learning: A Survey}},
    year = {2015},
    booktitle = {Foundations and Trends{\textregistered} in Machine Learning},
    author = {Ghavamzadeh, Mohammed and Mannor, Shie and Pineau, Joelle and Tamar, Aviv},
    number = {5-6},
    pages = {359--483},
    volume = {8},
    url = {http://www.nowpublishers.com/article/Details/MAL-049},
    isbn = {2200000049},
    doi = {10.1561/2200000049},
    issn = {1935-8237},
    pmid = {18255791},
    arxivId = {1405.4980}
}

@article{Kuleshov2014AlgorithmsProblems,
    title = {{Algorithms for multi-armed bandit problems}},
    year = {2014},
    author = {Kuleshov, Volodymyr and Precup, Doina},
    pages = {1--32},
    volume = {1},
    url = {http://arxiv.org/abs/1402.6028},
    isbn = {0-89871-605-5},
    doi = {10.1145/1109557.1109659},
    arxivId = {1402.6028}
}

@article{Cabras2007ExtremeFramework,
    title = {{Extreme Value Analysis within a Parametric Outlier Detection Framework}},
    year = {2007},
    journal = {Applied Stochastic Models in Business and Industry},
    author = {Cabras, S and Morales, J},
    number = {January},
    pages = {157--164},
    volume = {23},
    isbn = {15241904},
    doi = {10.1002/asmb},
    issn = {1524-1904},
    pmid = {35395390},
    keywords = {generalized pareto distribution, partial posterior predictive distribution, threshold selection}
}

@article{Vardakas2015AAlgorithms,
    title = {{A Survey on Demand Response Programs in Smart Grids: Pricing Methods and Optimization Algorithms}},
    year = {2015},
    journal = {IEEE Communications Surveys and Tutorials},
    author = {Vardakas, John S. and Zorba, Nizar and Verikoukis, Christos V.},
    number = {1},
    pages = {152--178},
    volume = {17},
    isbn = {1553-877X},
    doi = {10.1109/COMST.2014.2341586},
    issn = {1553877X},
    arxivId = {arXiv:1502.03908v1},
    keywords = {Smart grid, demand response, optimization algorithms, pricing methods}
}

@article{HalderOptimalLoads,
    title = {{Optimal Power Consumption for Demand Response of Thermostatically Controlled Loads}},
    author = {Halder, Abhishek and Geng, Xinbo and Fontes, Fernando A C C and Kumar, P R and Xie, Le},
    url = {https://arxiv.org/pdf/1609.07229.pdf},
    arxivId = {1609.07229}
}

@article{Lakshmanan2016ImpactExperiment,
    title = {{Impact of thermostatically controlled loads' demand response activation on aggregated power: A field experiment}},
    year = {2016},
    journal = {Energy},
    author = {Lakshmanan, Venkatachalam and Marinelli, Mattia and Kosek, Anna M. and N{\o}rg{\aa}rd, Per B. and Bindner, Henrik W.},
    pages = {705--714},
    volume = {94},
    publisher = {Elsevier Ltd},
    url = {http://dx.doi.org/10.1016/j.energy.2015.11.050},
    doi = {10.1016/j.energy.2015.11.050},
    issn = {03605442},
    keywords = {Aggregator, Demand response, Domestic energy resources, Flexible electricity demands, Load management, Smart grid}
}

@article{Auer2002b,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Auer, Peter and Cesa-Bianchi, Nicol{\`{o}} and Freund, Yoav and Schapire, Robert E.},
doi = {10.1137/S0097539701398375},
eprint = {arXiv:1011.1669v3},
file = {:Users/aksholokhov/Documents/Papers/Auer et al/2002/SIAM Journal on Computing/Auer et al. - 2002 - The Nonstochastic Multiarmed Bandit Problem.pdf:pdf},
isbn = {9788578110796},
issn = {0097-5397},
journal = {SIAM Journal on Computing},
keywords = {1995,331,68q32 68t05 91a20,adversarial bandit problem,ams subject classification,an early extended abstract,in the proceedings of,of this paper appeared,on founda-,pages 322,the 36th annual symposium,tions of computer science,unknown matrix games},
mendeley-groups = {Mathematics/Machine learning/Multiarmed Bandits},
month = {jan},
number = {1},
pages = {48--77},
pmid = {25246403},
title = {{The Nonstochastic Multiarmed Bandit Problem}},
url = {http://epubs.siam.org/doi/abs/10.1137/S0097539701398375 http://epubs.siam.org/doi/10.1137/S0097539701398375},
volume = {32},
year = {2002}
}



@inproceedings{Agrawal2015,
abstract = {We consider the linear contextual bandit problem with resource consumption, in addition to reward generation. In each round, the outcome of pulling an arm is a reward as well as a vector of resource consumptions. The expected values of these outcomes depend linearly on the context of that arm. The budget/capacity constraints require that the total consumption doesn't exceed the budget for each resource. The objective is once again to maximize the total reward. This problem turns out to be a common generalization of classic linear contextual bandits (linContextual), bandits with knapsacks (BwK), and the online stochastic packing problem (OSPP). We present algorithms with near-optimal regret bounds for this problem. Our bounds compare favorably to results on the unstructured version of the problem where the relation between the contexts and the outcomes could be arbitrary, but the algorithm only competes against a fixed set of policies accessible through an optimization oracle. We combine techniques from the work on linContextual, BwK, and OSPP in a nontrivial manner while also tackling new difficulties that are not present in any of these special cases.},
archivePrefix = {arXiv},
arxivId = {1507.06738},
author = {Agrawal, Shipra and Devanur, Nikhil R.},
eprint = {1507.06738},
file = {:Users/aksholokhov/Documents/Papers/Agrawal, Devanur/2015/Unknown/Agrawal, Devanur - 2015 - Linear Contextual Bandits with Knapsacks.pdf:pdf},
issn = {10495258},
mendeley-groups = {Bandits/Bandits with Knapsacks},
month = {jul},
number = {Nips},
title = {{Linear Contextual Bandits with Knapsacks}},
url = {http://arxiv.org/abs/1507.06738},
year = {2015}
}

@inproceedings{Badanidiyuru2013,
abstract = {Multi-armed bandit problems are the predominant theoretical model of exploration-exploitation tradeoffs in learning, and they have countless applications ranging from medical trials, to communication networks, to Web search and advertising. In many of these application domains the learner may be constrained by one or more supply (or budget) limits, in addition to the customary limitation on the time horizon. The literature lacks a general model encompassing these sorts of problems. We introduce such a model, called "bandits with knapsacks", that combines aspects of stochastic integer programming with online learning. A distinctive feature of our problem, in comparison to the existing regret-minimization literature, is that the optimal policy for a given latent distribution may significantly outperform the policy that plays the optimal fixed arm. Consequently, achieving sublinear regret in the bandits-with-knapsacks problem is significantly more challenging than in conventional bandit problems. We present two algorithms whose reward is close to the information-theoretic optimum: one is based on a novel "balanced exploration" paradigm, while the other is a primal-dual algorithm that uses multiplicative updates. Further, we prove that the regret achieved by both algorithms is optimal up to polylogarithmic factors. We illustrate the generality of the problem by presenting applications in a number of different domains including electronic commerce, routing, and scheduling. As one example of a concrete application, we consider the problem of dynamic posted pricing with limited supply and obtain the first algorithm whose regret, with respect to the optimal dynamic policy, is sublinear in the supply.},
archivePrefix = {arXiv},
arxivId = {1305.2545},
author = {Badanidiyuru, Ashwinkumar and Kleinberg, Robert and Slivkins, Aleksandrs},
booktitle = {2013 IEEE 54th Annual Symposium on Foundations of Computer Science},
doi = {10.1109/FOCS.2013.30},
eprint = {1305.2545},
file = {:Users/aksholokhov/Documents/Papers/Badanidiyuru, Kleinberg, Slivkins/2013/2013 IEEE 54th Annual Symposium on Foundations of Computer Science/Badanidiyuru, Kleinberg, Slivkins - 2013 - Bandits with Knapsacks.pdf:pdf},
isbn = {978-0-7695-5135-7},
issn = {02725428},
keywords = {Dynamic ad allocation,Dynamic pricing,Dynamic procurement,Exploration-exploitation tradeoff,Multi-armed bandits,Regret,Stochastic packing},
mendeley-groups = {Bandits/Bandits with Knapsacks},
month = {oct},
number = {May 2013},
pages = {207--216},
publisher = {IEEE},
title = {{Bandits with Knapsacks}},
url = {http://ieeexplore.ieee.org/document/6686156/},
year = {2013}
}

@inproceedings{Kalathil2015,
author = {Kalathil, Dileep and Rajagopal, Ram},
booktitle = {2015 53rd Annual Allerton Conference on Communication, Control, and Computing (Allerton)},
doi = {10.1109/ALLERTON.2015.7447007},
file = {:Users/aksholokhov/Documents/Papers/Kalathil, Rajagopal/2015/2015 53rd Annual Allerton Conference on Communication, Control, and Computing (Allerton)/Kalathil, Rajagopal - 2015 - Online learning for demand response.pdf:pdf},
isbn = {978-1-5090-1824-6},
keywords = {Cyber-Physical Systems,Machine Learning and Approximate Dynamic Programmi,Stochastic Systems and Control},
mendeley-groups = {Bandits and RL in DR},
month = {sep},
pages = {218--222},
publisher = {IEEE},
title = {{Online learning for demand response}},
url = {http://ieeexplore.ieee.org/document/7447007/},
year = {2015}
}

@inproceedings{Ruelens2014,
author = {Ruelens, Frederik and Claessens, Bert J. and Vandael, Stijn and Iacovella, Sandro and Vingerhoets, Pieter and Belmans, Ronnie},
booktitle = {2014 Power Systems Computation Conference},
doi = {10.1109/PSCC.2014.7038106},
file = {:Users/aksholokhov/Documents/Papers/Ruelens et al/2014/2014 Power Systems Computation Conference/Ruelens et al. - 2014 - Demand response of a heterogeneous cluster of electric water heaters using batch reinforcement learning.pdf:pdf},
isbn = {978-83-935801-3-2},
keywords = {Aggregator,batch reinforcement learning,demand response,electric water heater,fitted Q-iteration},
mendeley-groups = {Bandits and RL in DR},
month = {aug},
number = {2},
pages = {1--7},
publisher = {IEEE},
title = {{Demand response of a heterogeneous cluster of electric water heaters using batch reinforcement learning}},
url = {http://ieeexplore.ieee.org/document/7038106/},
year = {2014}
}

@article{Taylor2014,
author = {Taylor, Joshua A. and Mathieu, Johanna L.},
doi = {10.1109/TPWRS.2013.2289972},
file = {:Users/aksholokhov/Documents/Papers/Taylor, Mathieu/2014/IEEE Transactions on Power Systems/Taylor, Mathieu - 2014 - Index Policies for Demand Response.pdf:pdf},
isbn = {978-1-4673-5717-3},
issn = {0885-8950},
journal = {IEEE Transactions on Power Systems},
mendeley-groups = {Bandits and RL in DR},
month = {may},
number = {3},
pages = {1287--1295},
publisher = {IEEE},
title = {{Index Policies for Demand Response}},
url = {http://ieeexplore.ieee.org/document/6760879/ http://ieeexplore.ieee.org/document/6674094/},
volume = {29},
year = {2014}
}

@article{Wu2016,
author = {Wu, Xiaohua and Hu, Xiaosong and Moura, Scott and Yin, Xiaofeng and Pickert, Volker},
doi = {10.1016/j.jpowsour.2016.09.157},
file = {:Users/aksholokhov/Documents/Papers/Wu et al/2016/Journal of Power Sources/Wu et al. - 2016 - Stochastic control of smart home energy management with plug-in electric vehicle battery energy storage and photovolt.pdf:pdf},
isbn = {0378-7753},
issn = {03787753},
journal = {Journal of Power Sources},
keywords = {Batteries,Energy management,Photovoltaic array,Plug-in electric vehicle,Smart home,Stochastic dynamic optimization},
mendeley-groups = {Modelling of TCLs},
pages = {203--212},
publisher = {Elsevier B.V},
title = {{Stochastic control of smart home energy management with plug-in electric vehicle battery energy storage and photovoltaic array}},
url = {http://dx.doi.org/10.1016/j.jpowsour.2016.09.157},
volume = {333},
year = {2016}
}

@article{Arora2012,
author = {Arora, Sanjeev and Hazan, Elad and Kale, Satyen},
doi = {10.4086/toc.2012.v008a006},
issn = {1557-2862},
journal = {Theory of Computing},
keywords = {algorithms,game theory,machine learning},
pages = {121--164},
title = {{The Multiplicative Weights Update Method : A Meta-Algorithm and Applications}},
volume = {8},
year = {2012}
}


@article{EIA2009,
author = {EIA},
journal = {https://www.eia.gov/consumption/residential/},
mendeley-groups = {DR/Environment Protection},
title = {{Residential Energy Consumption Survey}},
year = {2009}
}



